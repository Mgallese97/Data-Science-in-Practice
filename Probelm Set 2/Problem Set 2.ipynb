{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center style=\"font-size:140%;\"> Report - Problem Set #*2*\n",
    " <center> Group Members:  Giacomo Martiriggiano, Mattia Gallese, Sophie De Becker, Yao Di"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook will outline the data cleaning process and binary classification for the churn factor of customers.csv for the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules needed for data analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn import svm\n",
    "#read the csv file to transfer all the data into \"data\"\n",
    "data = pd.read_csv('customers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We keep the data cleaning process as what we did for the Problem Set 1.\n",
    "The first step is to remove the empty value in the TotalCharges column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalCharges'] = data['TotalCharges'].replace(\" \", np.nan).astype('float32') \n",
    "data[\"SeniorCitizen\"]=data[\"SeniorCitizen\"].astype(\"object\")\n",
    "data = data[data[\"TotalCharges\"].notnull()]\n",
    "data = data.reset_index()[data.columns]\n",
    "#now we forced the 0 and 1 to be objects and we know we can drop the empty values in Total charger "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally a number may be non-empty but still unrealistic for example negative tenure. Let's now check that tenure and charges are non negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print((data['tenure'] <0).any())\n",
    "print((data['TotalCharges']<0).any())\n",
    "print((data['MonthlyCharges']<0).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode the inputs from enumerates to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_E2N = data[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'PhoneService', 'MultipleLines', 'InternetService',\n",
    "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "       'PaymentMethod','Churn']].copy()\n",
    "data_E2N = data_E2N.apply(lambda x: pd.factorize(x)[0])\n",
    "scaler = MinMaxScaler()\n",
    "data_E2N = pd.DataFrame(scaler.fit_transform(data_E2N),columns=data_E2N.columns)\n",
    "data_N = data[['tenure', 'MonthlyCharges', 'TotalCharges']].copy()\n",
    "data_N['TotalCharges'] = pd.to_numeric(data_N['TotalCharges'])\n",
    "scaler2 = StandardScaler()\n",
    "data_N = pd.DataFrame(scaler2.fit_transform(data_N),columns=data_N.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.concat([data_E2N, data_N], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Defination\n",
    "The key of the problem set is to develop a method to predict the performance of the customer. The prediction problem could be easily transfered to asup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key output of our supervised learning model is the \"Churn\" parameter. The first step is to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5163\n",
       "1.0    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could observe, the dataset is not balanced based on the churn parameter. In order to get a reliable result, we need to downsampling the No Churn set of customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_final, data_final[\"Churn\"], stratify=data_final[\"Churn\"],test_size=0.3)\n",
    "count_nochurn, count_churn = x_train[\"Churn\"].value_counts()\n",
    "\n",
    "x_train_nochurn = x_train[x_train['Churn'] == 0.0]\n",
    "x_train_churn = x_train[x_train['Churn'] == 1.0]\n",
    "\n",
    "x_train_nochurn_resample = x_train_nochurn.sample(count_churn)\n",
    "x_train_resample = pd.concat([x_train_nochurn_resample, x_train_churn], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Solving\n",
    "\n",
    "For the binary classification problem with multiple dimensions, support vector machine is a common solution to find a robust classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(gamma='auto')\n",
    "classifier.fit(x_train_resample.drop(columns=\"Churn\"), x_train_resample[\"Churn\"])\n",
    "y_predict=classifier.predict(x_test.drop(columns=\"Churn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for the classifier is : 0.7360189573459716\n",
      "The recall score for the classifier is : 0.8235294117647058\n",
      "The precision score for the classifier is :: 0.5021739130434782\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn_pred</th>\n",
       "      <th>No Churn_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Churn_true</th>\n",
       "      <td>462</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Churn_true</th>\n",
       "      <td>458</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Churn_pred  No Churn_pred\n",
       "Churn_true            462             99\n",
       "No Churn_true         458           1091"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The accuracy score for the classifier is :\",accuracy_score(y_test,y_predict))\n",
    "print(\"The recall score for the classifier is :\",recall_score(y_test,y_predict,labels=[1,0]))\n",
    "print(\"The precision score for the classifier is ::\",precision_score(y_test,y_predict,labels=[1,0]))\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict,labels=[1,0]), [\"Churn_true\",\"No Churn_true\"], [\"Churn_pred\",\"No Churn_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "We could add cross validation to ensure that our model is not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Churn_pred  No Churn_pred\n",
      "Churn_true            395             65\n",
      "No Churn_true         431            867\n",
      "               Churn_pred  No Churn_pred\n",
      "Churn_true            377             80\n",
      "No Churn_true         359            942\n",
      "               Churn_pred  No Churn_pred\n",
      "Churn_true            370             96\n",
      "No Churn_true         437            855\n",
      "               Churn_pred  No Churn_pred\n",
      "Churn_true            394             92\n",
      "No Churn_true         400            872\n",
      "The accuracy scores for the  4 -fold classifier is : [0.7178612059158134, 0.7502844141069397, 0.6968145620022753, 0.7201365187713311]\n",
      "The recall scores for the  4 -fold classifier is : [0.8586956521739131, 0.824945295404814, 0.7939914163090128, 0.8106995884773662]\n",
      "The precision scores for the  4 -fold classifier is : [0.4782082324455206, 0.5122282608695652, 0.45848822800495664, 0.49622166246851385]\n"
     ]
    }
   ],
   "source": [
    "Accuracy_scores = []\n",
    "Recall_scores = []\n",
    "Precision_scores = []\n",
    "\n",
    "k = 4\n",
    "classifier = svm.SVC(gamma='auto')\n",
    "cv = KFold(n_splits=k, random_state=42, shuffle=False)\n",
    "for train_index, test_index in cv.split(data_final):\n",
    "    x_train, x_test, y_train, y_test = data_final.iloc[train_index], data_final.iloc[test_index], data_final.Churn.iloc[train_index], data_final.Churn.iloc[test_index]\n",
    "    \n",
    "    x_train_nochurn = x_train[x_train['Churn'] == 0.0]\n",
    "    x_train_churn = x_train[x_train['Churn'] == 1.0]\n",
    "\n",
    "    x_train_nochurn_resample = x_train_nochurn.sample(count_churn)\n",
    "    x_train_resample = pd.concat([x_train_nochurn_resample, x_train_churn], axis=0)\n",
    "    \n",
    "    classifier.fit(x_train_resample.drop(columns=\"Churn\"), x_train_resample[\"Churn\"])\n",
    "    y_predict=classifier.predict(x_test.drop(columns=\"Churn\"))\n",
    "    Accuracy_scores.append(accuracy_score(y_test,y_predict))\n",
    "    Recall_scores.append(recall_score(y_test,y_predict,labels=[1,0]))\n",
    "    Precision_scores.append(precision_score(y_test,y_predict,labels=[1,0]))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test,y_predict,labels=[1,0]), [\"Churn_true\",\"No Churn_true\"], [\"Churn_pred\",\"No Churn_pred\"]))\n",
    "\n",
    "print(\"The accuracy scores for the \",k, \"-fold classifier is :\",Accuracy_scores)\n",
    "print(\"The recall scores for the \",k, \"-fold classifier is :\",Recall_scores)\n",
    "print(\"The precision scores for the \",k, \"-fold classifier is :\",Precision_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 3, 10, 30, 100], 'kernel': ['linear']},\n",
    "  {'C': [1, 3, 10, 30, 100], 'kernel': ['rbf'], 'gamma': [0.0001, 0.0003, 0.001]}, \n",
    " ]\n",
    "svc = svm.SVC()\n",
    "classifier=GridSearchCV(svc,param_grid,cv=k)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_final, data_final[\"Churn\"], stratify=data_final[\"Churn\"],test_size=0.3)\n",
    "count_nochurn, count_churn = x_train[\"Churn\"].value_counts()\n",
    "\n",
    "x_train_nochurn = x_train[x_train['Churn'] == 0.0]\n",
    "x_train_churn = x_train[x_train['Churn'] == 1.0]\n",
    "\n",
    "x_train_nochurn_resample = x_train_nochurn.sample(count_churn)\n",
    "x_train_resample = pd.concat([x_train_nochurn_resample, x_train_churn], axis=0)\n",
    "\n",
    "classifier.fit(x_train_resample.drop(columns=\"Churn\"), x_train_resample[\"Churn\"])\n",
    "y_predict=classifier.predict(x_test.drop(columns=\"Churn\"))\n",
    "\n",
    "print(\"The accuracy score for the best classifier is :\",accuracy_score(y_test,y_predict))\n",
    "print(\"The recall score for the best classifier is :\",recall_score(y_test,y_predict,labels=[1,0]))\n",
    "print(\"The precision score for the best classifier is ::\",precision_score(y_test,y_predict,labels=[1,0]))\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict,labels=[1,0]), [\"Churn_true\",\"No Churn_true\"], [\"Churn_pred\",\"No Churn_pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
