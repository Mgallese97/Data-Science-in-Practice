{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center style=\"font-size:140%;\"> Report - Problem Set #*2*\n",
    " <center> Group Members:  Giacomo Martiriggiano, Mattia Gallese, Sophie De Becker, Yao Di"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook will outline the data cleaning process and binary classification for the churn factor of customers.csv for the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules needed for data analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn import svm\n",
    "#read the csv file to transfer all the data into \"data\"\n",
    "data = pd.read_csv('customers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We keep the data cleaning process as what we did for the Problem Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalCharges'] = data['TotalCharges'].replace(\" \", np.nan).astype('float32') \n",
    "data[\"SeniorCitizen\"]=data[\"SeniorCitizen\"].astype(\"object\")\n",
    "data = data[data[\"TotalCharges\"].notnull()]\n",
    "data = data.reset_index()[data.columns]\n",
    "#now we forced the 0 and 1 to be objects and we know we can drop the empty values in Total charger "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally a number may be non-empty but still unrealistic for example negative tenure. Let's now check that tenure and charges are non negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print((data['tenure'] <0).any())\n",
    "print((data['TotalCharges']<0).any())\n",
    "print((data['MonthlyCharges']<0).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode the inputs from enumerates to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_E2N = data[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'PhoneService', 'MultipleLines', 'InternetService',\n",
    "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "       'PaymentMethod','Churn']].copy()\n",
    "data_E2N = data_E2N.apply(lambda x: pd.factorize(x)[0])\n",
    "scaler = MinMaxScaler()\n",
    "data_E2N = pd.DataFrame(scaler.fit_transform(data_E2N),columns=data_E2N.columns)\n",
    "data_N = data[['tenure', 'MonthlyCharges', 'TotalCharges']].copy()\n",
    "data_N['TotalCharges'] = pd.to_numeric(data_N['TotalCharges'])\n",
    "scaler2 = StandardScaler()\n",
    "data_N = pd.DataFrame(scaler2.fit_transform(data_N),columns=data_N.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numerized = pd.concat([data_E2N, data_N], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "data_final = pd.DataFrame(scaler.fit_transform(data_numerized),columns=data_numerized.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Defination\n",
    "The key of the problem set is to develop a method to predict the performance of the customer. The prediction problem could be easily transfered to asup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key output of our supervised learning model is the \"Churn\" parameter. The first step is to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5163\n",
       "1.0    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could observe, the dataset is not balanced based on the churn parameter. In order to get a reliable result, we need to downsampling the No Churn set of customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_final, data_final[\"Churn\"], stratify=data_final[\"Churn\"],test_size=0.3)\n",
    "count_nochurn, count_churn = x_train[\"Churn\"].value_counts()\n",
    "\n",
    "x_train_nochurn = x_train[x_train['Churn'] == 0.0]\n",
    "x_train_churn = x_train[x_train['Churn'] == 1.0]\n",
    "\n",
    "x_train_nochurn_resample = x_train_nochurn.sample(count_churn)\n",
    "x_train_resample = pd.concat([x_train_nochurn_resample, x_train_churn], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Solving\n",
    "\n",
    "For the binary classification problem with multiple dimensions, support vector machine is a common solution to find a robust classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(gamma='auto')\n",
    "classifier.fit(x_train_resample.drop(columns=\"Churn\"), x_train_resample[\"Churn\"])\n",
    "y_predict=classifier.predict(x_test.drop(columns=\"Churn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for the classifier is : 0.718957345971564\n",
      "The recall score for the classifier is : 0.8163992869875223\n",
      "The precision score for the classifier is :: 0.4831223628691983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn_pred</th>\n",
       "      <th>No Churn_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Churn_true</th>\n",
       "      <td>458</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Churn_true</th>\n",
       "      <td>490</td>\n",
       "      <td>1059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Churn_pred  No Churn_pred\n",
       "Churn_true            458            103\n",
       "No Churn_true         490           1059"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The accuracy score for the classifier is :\",accuracy_score(y_test,y_predict))\n",
    "print(\"The recall score for the classifier is :\",recall_score(y_test,y_predict,labels=[1,0]))\n",
    "print(\"The precision score for the classifier is ::\",precision_score(y_test,y_predict,labels=[1,0]))\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict,labels=[1,0]), [\"Churn_true\",\"No Churn_true\"], [\"Churn_pred\",\"No Churn_pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could add cross validation to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Churn_pred  No Churn_pred\n",
      "Churn_true            398             62\n",
      "No Churn_true         438            860\n",
      "               Churn_pred  No Churn_pred\n",
      "Churn_true            390             67\n",
      "No Churn_true         402            899\n",
      "               Churn_pred  No Churn_pred\n",
      "Churn_true            374             92\n",
      "No Churn_true         477            815\n",
      "               Churn_pred  No Churn_pred\n",
      "Churn_true            398             88\n",
      "No Churn_true         418            854\n",
      "The accuracy scores for the  4 -fold classifier is : [0.7155858930602957, 0.7332195676905574, 0.6763367463026166, 0.7121729237770194]\n",
      "The recall scores for the  4 -fold classifier is : [0.8652173913043478, 0.8533916849015317, 0.8025751072961373, 0.8189300411522634]\n",
      "The precision scores for the  4 -fold classifier is : [0.47607655502392343, 0.49242424242424243, 0.4394829612220917, 0.4877450980392157]\n"
     ]
    }
   ],
   "source": [
    "Accuracy_scores = []\n",
    "Recall_scores = []\n",
    "Precision_scores = []\n",
    "\n",
    "k = 4\n",
    "classifier = svm.SVC(gamma='auto')\n",
    "cv = KFold(n_splits=k, random_state=42, shuffle=False)\n",
    "for train_index, test_index in cv.split(data_final):\n",
    "    x_train, x_test, y_train, y_test = data_final.iloc[train_index], data_final.iloc[test_index], data_final.Churn.iloc[train_index], data_final.Churn.iloc[test_index]\n",
    "    \n",
    "    x_train_nochurn = x_train[x_train['Churn'] == 0.0]\n",
    "    x_train_churn = x_train[x_train['Churn'] == 1.0]\n",
    "\n",
    "    x_train_nochurn_resample = x_train_nochurn.sample(count_churn)\n",
    "    x_train_resample = pd.concat([x_train_nochurn_resample, x_train_churn], axis=0)\n",
    "    \n",
    "    classifier.fit(x_train_resample.drop(columns=\"Churn\"), x_train_resample[\"Churn\"])\n",
    "    y_predict=classifier.predict(x_test.drop(columns=\"Churn\"))\n",
    "    Accuracy_scores.append(accuracy_score(y_test,y_predict))\n",
    "    Recall_scores.append(recall_score(y_test,y_predict,labels=[1,0]))\n",
    "    Precision_scores.append(precision_score(y_test,y_predict,labels=[1,0]))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test,y_predict,labels=[1,0]), [\"Churn_true\",\"No Churn_true\"], [\"Churn_pred\",\"No Churn_pred\"]))\n",
    "\n",
    "print(\"The accuracy scores for the \",k, \"-fold classifier is :\",Accuracy_scores)\n",
    "print(\"The recall scores for the \",k, \"-fold classifier is :\",Recall_scores)\n",
    "print(\"The precision scores for the \",k, \"-fold classifier is :\",Precision_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
