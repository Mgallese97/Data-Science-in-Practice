{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> What makes a song a hit? \n",
    "    \n",
    "### <center> Data Science in Practice\n",
    "   Authors:\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix , classification_report, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix,average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides keeping all the music quality features we used in out classifier model, we try to understand which kinds of time-series data could be introduced to our regressor.  \n",
    "\n",
    "Normally, the Spotify users may try to listen the songs which has already been popular. Therefore, we introduce the new features recording the stream in the last 5 appearances in the list and the position in the last list.  \n",
    "\n",
    "However, if the popular song stays too long on the top lists, the user may consider it “out-of-fashion” and streams less. In order to take this case into consideration, we introduced two other features: \n",
    "\n",
    "Week-count: count how many times the song has been in the top 200 list \n",
    "Week-prev: when was the last time the song appeared in the top 200 list.  \n",
    "Week: current week of the estimation, working together with the week-prev, we could observe if the song has felt out of the list in the past period. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Feature Selection & Dynamic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall_fe = dfall.copy()\n",
    "dfall_fe = dfall_fe.drop(columns = ['URL', 'uri','track_href','analysis_url','type','Track Name'])\n",
    "dfall_fe_id_values = dfall_fe.id.unique().tolist()\n",
    "cdff = ['counts','index_prev','week_prev','pos_prev','stream_prev']\n",
    "vdff = np.empty((len(dfall_fe_id_values),len(cdff)))\n",
    "vdff[:] = np.nan\n",
    "dfFeature = pd.DataFrame(vdff, \n",
    "                         index =dfall_fe_id_values, columns = cdff)\n",
    "dfall_fe['hist'] = [0]*len(dfall_fe.index)\n",
    "dfall_fe['new'] = [0]*len(dfall_fe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dfall_fe.shape[0]):\n",
    "    if np.isnan(dfFeature.at[dfall_fe.id[i],'counts']):\n",
    "        dfall_fe.at[i,'new'] = 1\n",
    "        dfall_fe.at[i,'hist'] = 1\n",
    "        dfFeature.at[dfall_fe.id[i],'counts'] = 1\n",
    "        dfFeature.at[dfall_fe.id[i],'stream_prev'] = dfall_fe.at[i,'Streams']\n",
    "        dfFeature.at[dfall_fe.id[i],'stream_log1'] = dfall_fe.at[i,'Streams']\n",
    "        dfFeature.at[dfall_fe.id[i],'stream_log2'] = dfall_fe.at[i,'Streams']\n",
    "        dfFeature.at[dfall_fe.id[i],'stream_log3'] = dfall_fe.at[i,'Streams']\n",
    "        dfFeature.at[dfall_fe.id[i],'stream_log4'] = dfall_fe.at[i,'Streams']\n",
    "        dfall_fe.at[i,'week_prev'] = 0\n",
    "        dfall_fe.at[i,'stream_prev'] = 0\n",
    "        dfall_fe.at[i,'pos_prev'] = 200\n",
    "        \n",
    "    else:\n",
    "        dfFeature.at[dfall_fe.id[i],'counts'] += 1\n",
    "        dfall_fe.at[i,'week_prev'] = dfFeature.at[dfall_fe.id[i],'week_prev']\n",
    "        dfall_fe.at[i,'stream_prev'] = dfFeature.at[dfall_fe.id[i],'stream_prev']\n",
    "        dfall_fe.at[i,'stream_prev'] = dfFeature.at[dfall_fe.id[i],'stream_prev']\n",
    "        dfall_fe.at[i,'pos_prev'] = dfFeature.at[dfall_fe.id[i],'pos_prev']\n",
    "        dfall_fe.at[i,'hist'] = dfFeature.at[dfall_fe.id[i],'counts']\n",
    "    dfFeature.at[dfall_fe.id[i],'index_prev'] = i\n",
    "    dfFeature.at[dfall_fe.id[i],'week_prev'] = dfall_fe.at[i,'week']\n",
    "    dfFeature.at[dfall_fe.id[i],'stream_log4'] = dfFeature.at[dfall_fe.id[i],'stream_log3']\n",
    "    dfFeature.at[dfall_fe.id[i],'stream_log3'] = dfFeature.at[dfall_fe.id[i],'stream_log2']\n",
    "    dfFeature.at[dfall_fe.id[i],'stream_log2'] = dfFeature.at[dfall_fe.id[i],'stream_log1']\n",
    "    dfFeature.at[dfall_fe.id[i],'stream_log1'] = dfFeature.at[dfall_fe.id[i],'stream_prev']\n",
    "    dfFeature.at[dfall_fe.id[i],'stream_prev'] = dfall_fe.at[i,'Streams']\n",
    "    dfFeature.at[dfall_fe.id[i],'pos_prev'] = dfall_fe.at[i,'Position']\n",
    "    dfall_fe.at[i,'stream_avg'] = 1/5*(dfall_fe.at[i,'Streams'] + dfFeature.at[dfall_fe.id[i],'stream_prev']\n",
    "                                      + dfFeature.at[dfall_fe.id[i],'stream_log1']+ dfFeature.at[dfall_fe.id[i],'stream_log2']\n",
    "                                      + dfFeature.at[dfall_fe.id[i],'stream_log3']+ dfFeature.at[dfall_fe.id[i],'stream_log4'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Feature Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['danceability','energy','key','loudness','mode' ,'speechiness','acousticness','instrumentalness','liveness','valence','tempo','new','week','week_prev','pos_prev','stream_prev','duration_ms']    \n",
    "X_orig = dfall_fe[features]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x = X_orig.values #returns a numpy array\n",
    "std_scaler = StandardScaler()\n",
    "x_scaled = std_scaler.fit_transform(x)\n",
    "\n",
    "X_scaled = pd.DataFrame(x_scaled, columns = features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polynormial_features_set(X_scaled, k ):\n",
    "    x_scaled = X_scaled.to_numpy()\n",
    "    features = X_scaled.columns.tolist()\n",
    "    for order in range(2,k+1):\n",
    "        features_tmp = features\n",
    "        for i in range(len(features)):\n",
    "            features_tmp[i]= features[i]+'_'+str(order)\n",
    "            x_tmp = x_scaled**order\n",
    "        X_tmp = pd.DataFrame(x_tmp, columns = features_tmp) \n",
    "        if order == 2:\n",
    "            X_poly = X_tmp\n",
    "        else:\n",
    "            X_poly = pd.concat([X_poly, X_tmp], axis=1).reindex(X_poly.index)\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position Prediction – Use Regression to Classify the Top Songs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the limitations in our classification model is that the unbalanced dataset will generate the estimation bias. Although we could use some sampling approaches to generate a balanced dataset, new bias could be introduced during the process.  \n",
    "\n",
    "As the classification object “Top” is based on the value “Position”, one of the possible solutions is to change the classification problem to a regression problem on “Position”. The classification will be done based on the predicted “Position” value.  \n",
    "\n",
    "Different from the approach in our classification model, as the position is a time-dependent value, the model will be week-based. Some dynamic features will be introduced to improve the accuracy of the time series approach.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_scaled\n",
    "y = dfall['Position']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regr = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred_train = regr.predict(X_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Test Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print('Train Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_train, y_pred_train))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = generate_polynormial_features_set(X_scaled, 4)\n",
    "X = pd.concat([X_scaled, X_poly], axis=1).reindex(X_scaled.index)\n",
    "y = dfall['Position']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regr = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred_train = regr.predict(X_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Test Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print('Train Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_train, y_pred_train))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full features regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sqrt = features\n",
    "for i in range(len(features)):\n",
    "    features_sqrt[i]= features[i]+'_sqrt'\n",
    "\n",
    "x_sqrt = np.sqrt(np.abs(x_scaled))\n",
    "X_sqrt = pd.DataFrame(x_sqrt, columns = features_sqrt) \n",
    "\n",
    "features_sin = features\n",
    "for i in range(len(features)):\n",
    "    features_sin[i]= features[i]+'_sin'\n",
    "\n",
    "x_sin = np.sin(x_scaled)\n",
    "X_sin = pd.DataFrame(x_sin, columns = features_sin) \n",
    "\n",
    "features_cos = features\n",
    "for i in range(len(features)):\n",
    "    features_cos[i]= features[i]+'_cos'\n",
    "\n",
    "x_cos = np.cos(x_scaled)\n",
    "X_cos = pd.DataFrame(x_cos, columns = features_cos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_scaled, X_poly, X_sqrt, X_sin, X_cos], axis=1).reindex(X_scaled.index)\n",
    "y = dfall['Position']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regr = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred_train = regr.predict(X_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Test Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print('Train Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_train, y_pred_train))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression to Full features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_clf = pd.DataFrame(y_test)\n",
    "y_test_clf['top'] = np.where(y_test_clf['Position']<dfall.Position.quantile(0.2), 1, 0)\n",
    "y_pred_clf = pd.DataFrame(data = y_pred, columns = ['Position'])\n",
    "y_pred_clf['top'] = np.where(y_pred_clf['Position']<dfall.Position.quantile(0.2), 1, 0)\n",
    "\n",
    "mat = confusion_matrix(y_test_clf['top'], y_pred_clf['top'])\n",
    "s1=sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "          xticklabels=['No','Yes'],\n",
    "          yticklabels=['No','Yes'] )\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "bottom, top = s1.get_ylim()\n",
    "s1.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "print(\"Accuracy Score:\",accuracy_score(y_test_clf['top'],y_pred_clf['top']))\n",
    "print(\"Recall Score:\",recall_score(y_test_clf['top'],y_pred_clf['top'],labels=[1,0]))\n",
    "print(\"Precision Score:\",precision_score(y_test_clf['top'],y_pred_clf['top'],labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression based on Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the current business model of Spotify, streaming number is the decisive factor for the singer's profit. We could therefore predict the future number of streams as the estimative indicator for the singer's profit from spotify. \n",
    "\n",
    "The problem could be defined as a regression problem with continious output variable rather than binary-classfication. Therefore, We need to choose different models with different feature set for this problem. The coefficient of determination is chosen as the measure on the performance of our regressor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 4.48258270e+04 -7.08489351e+04 -8.33593504e+03  3.02753903e+04\n",
      " -6.97697564e+03 -2.78033578e+04 -1.11905228e+04  3.76281273e+03\n",
      "  1.15042939e+04 -3.03932010e+03 -5.09047953e+02  1.08969128e+06\n",
      " -2.68470009e+04  5.53897483e+04 -9.74545814e+04  1.74375184e+06\n",
      " -2.08165968e+04]\n",
      "Test Mean squared error: 1624025882432.18\n",
      "Train Mean squared error: 1637912832055.08\n",
      "Coefficient of determination: 0.63\n"
     ]
    }
   ],
   "source": [
    "X = X_scaled\n",
    "y = dfall['Streams']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regr = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred_train = regr.predict(X_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Test Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print('Train Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_train, y_pred_train))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynormial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 3.57387558e+04 -7.05321814e+04  7.22694469e+04  3.21968940e+04\n",
      "  2.57659912e+01 -1.29834188e+04  3.09494942e+04 -5.73547758e+04\n",
      " -3.48121321e+04 -5.41960366e+04  1.20207032e+04  2.12861792e+03\n",
      " -4.74083147e+05  9.79908739e+05 -7.41430504e+04  1.48431858e+06\n",
      " -9.59323461e+03 -2.47087225e+03 -1.41871489e+04 -1.47698599e+05\n",
      "  1.91165014e+04 -1.01823997e+01 -3.39729074e+04  3.29200641e+03\n",
      "  2.41114014e+04  4.23610741e+04 -4.82453232e+04 -1.42344535e+04\n",
      "  4.82583737e+03  1.04653798e+06 -1.24275821e+06 -2.54141628e+05\n",
      " -8.39486218e+04 -7.92186810e+03 -7.13541992e+03 -3.96726849e+03\n",
      " -4.70087253e+04 -1.91961035e+03  2.97897491e+01  1.60568280e+04\n",
      " -3.05612305e+04 -2.25875000e+03 -6.03628101e+03  1.82800033e+04\n",
      " -1.01013775e+04  1.30693823e+04  1.78086457e+05 -7.06102698e+05\n",
      " -9.13294762e+04  8.45706030e+03  4.28005371e+02 -2.31507373e+03\n",
      " -2.27126721e+03  4.74250677e+04 -6.68660156e+02 -2.19549484e+01\n",
      " -1.90813281e+03  6.54166406e+03  6.92500000e+01 -1.53169922e+02\n",
      "  9.46396527e+03  7.45281305e+03  3.44557273e+04 -4.17026051e+05\n",
      "  6.98989848e+05  2.30648168e+05  2.81410156e+02 -2.42734375e+01]\n",
      "Test Mean squared error: 1372449152802.35\n",
      "Train Mean squared error: 1640702982439.35\n",
      "Coefficient of determination: 0.65\n"
     ]
    }
   ],
   "source": [
    "X_poly = generate_polynormial_features_set(X_scaled, 4)\n",
    "X = pd.concat([X_scaled, X_poly], axis=1).reindex(X_scaled.index)\n",
    "y = dfall['Streams']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regr = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred_train = regr.predict(X_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Test Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print('Train Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_train, y_pred_train))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression on Full features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 1.97340796e+06  8.16513070e+05  2.40734265e+05  3.93371666e+05\n",
      "  1.83704865e+02  2.07560739e+05  6.04804222e+06 -7.23048481e+03\n",
      " -4.47213613e+05 -8.67869697e+05 -1.12736586e+06  3.74953450e+03\n",
      " -2.72652038e+07  3.88448508e+07  2.83289802e+07  2.63375767e+06\n",
      "  5.23351316e+04  5.44907988e+05  3.11671277e+05 -8.17482919e+06\n",
      " -8.94300308e+04 -7.25979614e+01 -5.54107012e+04 -3.15587904e+06\n",
      "  4.22960347e+04 -3.03904867e+05  3.10165238e+06  3.32689701e+06\n",
      "  8.50065497e+03 -2.96519474e+06 -2.04282064e+07 -5.60291149e+07\n",
      " -1.10789263e+06 -2.11529608e+03 -2.79011301e+05 -1.20539985e+05\n",
      " -7.56498376e+04 -7.17148962e+04  2.12394623e+02 -1.12223491e+04\n",
      " -9.09825059e+05 -4.18072852e+03  1.47156338e+05  1.38324176e+05\n",
      "  1.57222474e+05  2.30215535e+04  3.98875533e+06 -6.26264179e+06\n",
      " -4.27305665e+06  1.83240140e+05 -6.25904150e+03 -6.35507747e+04\n",
      " -3.10661603e+04  6.37372594e+05 -7.20333203e+03 -1.56533905e+02\n",
      "  2.03636523e+03  2.91100552e+05  1.06671875e+02 -1.40884971e+04\n",
      " -2.13315336e+05 -2.17173629e+05  6.06933503e+04 -1.28676866e+05\n",
      "  2.26595949e+06  4.42113461e+06 -8.44707812e+03  4.18529785e+02\n",
      " -3.08813835e+05 -1.37038660e+05 -2.80631246e+04 -1.13302024e+05\n",
      " -1.77198181e+01  5.88362877e+04  2.12621077e+05 -3.07732142e+05\n",
      "  9.44386329e+04  3.29587082e+04  1.30155374e+05  1.25456150e+03\n",
      " -5.37945970e+05 -7.58617784e+03  1.45307557e+05  6.19395379e+05\n",
      " -4.03409242e+04 -1.97461813e+06 -8.98325996e+05 -1.54924691e+05\n",
      " -3.33900077e+05  1.50517441e+02 -2.28428720e+05 -6.07088049e+06\n",
      "  5.99151242e+04  3.51061497e+05  8.17038131e+05  1.14444608e+06\n",
      "  1.04849130e+03  2.72410719e+07 -3.82959786e+07 -2.86444504e+07\n",
      " -9.79984028e+05 -6.36648485e+04  7.23648302e+05  5.20094502e+05\n",
      " -1.62675279e+07 -3.93915890e+05  3.01345406e+01  1.52400925e+04\n",
      " -5.94178874e+06 -1.03719453e+05 -6.16776049e+05  6.45731712e+06\n",
      "  6.99704042e+06 -2.24320741e+03 -8.60429551e+06 -3.81940255e+07\n",
      " -1.12214109e+08 -2.08520411e+05 -1.40881062e+04]\n",
      "Test Mean squared error: 1558658100516.42\n",
      "Train Mean squared error: 1566186031785.50\n",
      "Coefficient of determination: 0.63\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([X_scaled, X_poly, X_sqrt, X_sin, X_cos], axis=1).reindex(X_scaled.index)\n",
    "y = dfall['Streams']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regr = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred_train = regr.predict(X_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Test Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print('Train Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_train, y_pred_train))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ydi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean squared error: 5405677940613.91\n",
      "Train Mean squared error: 4699251964268.54\n",
      "Coefficient of determination: -0.12\n"
     ]
    }
   ],
   "source": [
    "X_poly = generate_polynormial_features_set(X_scaled, 4)\n",
    "X = pd.concat([X_scaled, X_poly], axis=1).reindex(X_scaled.index)\n",
    "y = dfall['Streams']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "regr = svm.SVR()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred_train = regr.predict(X_train)\n",
    "\n",
    "# The mean squared error\n",
    "print('Test Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print('Train Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_train, y_pred_train))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
